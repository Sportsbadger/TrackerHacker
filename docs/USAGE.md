# TrackerHacker Usage Guide

This guide explains what TrackerHacker does, how to run it interactively, and how to script it programmatically. Examples assume Python 3.10+ and UTF-8 CSV exports from Sitetracker.

## What the tool does
- Validates Sitetracker tracker exports for required columns and malformed JSON in the `Filters` column.
- Audits trackers for canonical field usage across `Fields`, `Filters`, `Logic`, `Query`, `Formatting`, `OrderBy(Long)`, `ResizeMap`, and `Label Map`.
- Applies removals, swaps, and additions to tracker definitions while keeping timestamped backups.
- Restores a tracker to an earlier state using a tracker history CSV and produces a restore report.

## Input expectations
- **Encoding**: Prefer `utf-8` or `utf-8-sig`. Mismatched encodings can surface as malformed characters in columns such as `Filters` or `Logic`.
- **Delimiter and quoting**: Files must be comma-delimited with quotes around fields that contain commas or JSON content (for example, `Filters`). The CLI uses `pandas.read_csv`, so quoting rules must be standard.
- **Primary export CSV (required)**: Must include columns listed in [Required CSV columns](../README.md#required-csv-columns). The loader rejects the file and reports any missing columns before further work begins.
- **Optional helper files**:
  - **Swap pairs CSV**: Maps legacy field API names to replacements via `OldFieldAPI` and `NewFieldAPI` columns.
  - **Audit removal CSV**: Generated by audits; maps `Tracker Name Id` to contextual fields that should be removed.
  - **Tracker history CSV**: Contains `Tracker`, `id Tracker`, `Modify Date`, and field change columns (for example, `Field`/`API Field`, `Old Value`, `New Value`). Used only for restoration.

## Running the CLI
From the repository root:

```bash
python TrackerHacker.py
```

You will be prompted for the Sitetracker export CSV path (or a directory containing it). If a directory has multiple CSVs, the CLI asks you to pick one. Successful load prints how many trackers were read and the source filename.

### Main menu actions
After loading data you will see the main menu. Every action is interrupt-safeâ€”press `Ctrl+C` to return to the menu.

1. **Load New Source Data**
   - Replaces the in-memory dataframe with a new export.
   - Use this before every workflow if you want a fresh baseline.

2. **Remove Fields (from Audit file)**
   - Purpose: remove canonical fields flagged by a prior audit. Use when audits produced a CSV with contextual paths to drop.
   - Flow:
     1. Select the audit CSV (direct path or directory with candidates).
     2. The CLI maps `Tracker Name Id` to the contextual field paths listed in `(as <field>) - Columns` headers.
     3. Select rows to modify; the tool strips fields from `Fields`, prunes related `Filters`, rebuilds `Logic`/`Query`, and updates formatting maps.
     4. Outputs: timestamped `modified_<timestamp>.csv` plus a `backup_<timestamp>.csv` copy of untouched rows in `outputs/`.

3. **Swap Fields**
   - Purpose: replace deprecated field API names with new ones.
   - Flow options:
     - **Manual pairs**: enter `OldFullFieldAPI,NewFullFieldAPI` repeatedly; blank line ends entry.
     - **CSV-driven**: load a swap-pairs CSV containing `OldFieldAPI` and `NewFieldAPI` columns.
   - When a swap target already exists in a row, the tool converts the swap into a removal to avoid duplicates. Filters, `Logic`, `Query`, `Formatting`, and `ResizeMap` references are updated consistently.

4. **Add Field**
   - Purpose: ensure canonical fields appear in the `Fields` column. Useful after adding new calculated fields.
   - Flow: enter one or more fully qualified field paths; the CLI appends missing entries to `Fields` for selected rows.

5. **Audit Fields**
   - Purpose: locate trackers that reference specified canonical fields anywhere in their definitions.
   - Flow:
     1. Enter one or more canonical field names (partial names are matched contextually across columns).
     2. The CLI produces a detailed per-column CSV report (timestamped as `audit_<timestamp>.csv`) written to `outputs/`.
     3. You are prompted to open the report immediately after it is saved.

6. **Restore Tracker from History**
   - Purpose: reconstruct a tracker row to its state at a specific `Modify Date` using a history CSV.
   - Flow:
     1. Choose a tracker history CSV (file or directory selection supported).
     2. Pick the **Tracker** by its human-readable name and a target `Modify Date` timestamp.
     3. Review the computed restore option; optionally apply it to the in-memory dataframe.
     4. Outputs: human-readable restore report and a CSV snapshot of the restored row in `outputs/`.

7. **Exit**
   - Cleanly ends the session. The tool creates `outputs/` automatically and never overwrites prior runs because filenames are timestamped.

### Example CLI session (audit then modify)
```
$ python TrackerHacker.py
--- Sitetracker Tracker Modifier Tool ---
Path to Sitetracker CSV export (or directory containing it): ./exports
Automatically selected data CSV: tracker_export.csv
Successfully loaded 42 trackers from 'tracker_export.csv'.

--- Main Menu ---
Currently loaded data: 42 trackers from 'tracker_export.csv'.
Select action: Audit Fields
Audit canonical field names (e.g., Status__c) (comma-separated): Project__c.Status__c, Site__c.Type__c
Audit saved to outputs/audit_20240520153000.csv
Open audit report? [y/N]: n

--- Main Menu ---
Select action: Remove Fields (from Audit file)
Path to Audit CSV (or directory): outputs
Select audit file: audit_20240520153000.csv
Select trackers to modify: [All trackers with matches]
Processing 3 selected trackers...
Modified trackers written to outputs/modified_20240520154500.csv
Unmodified backups written to outputs/backup_20240520154500.csv
```

## Programmatic examples
Use these snippets if you prefer scripts instead of the interactive CLI.

### Audit and summarize matches
```python
from pathlib import Path
import pandas as pd
from tracker_hacker.audit import master_audit
from tracker_hacker.constants import REQUIRED_COLUMNS

source = Path("./exports/tracker_export.csv")
df = pd.read_csv(source, dtype={"Tracker Name Id": str})
missing = [col for col in REQUIRED_COLUMNS if col not in df.columns]
if missing:
    raise ValueError(f"Missing required columns: {missing}")

canonical = ["Project__c.Status__c", "Site__c.Type__c"]
report = master_audit(df, canonical, detailed_report=True)
# `report` is a dict keyed by tracker index with per-column occurrences.
```

### Identify and apply modifications
```python
from pathlib import Path
import pandas as pd
from tracker_hacker.modifications import identify_modifications, modify_trackers

source = Path("./exports/tracker_export.csv")
df = pd.read_csv(source, dtype={"Tracker Name Id": str})
fields_to_remove = ["Project__c.Status__c"]
swap_map = {"Site__c.Type__c": "Site__c.Category__c"}
fields_to_add = ["Project__c.Flag__c"]

mods = identify_modifications(df, fields_to_remove, swap_map, fields_to_add)
rows_to_change = list(mods)

output_dir = Path("./outputs")
output_dir.mkdir(exist_ok=True)
timestamp = "20240520160000"
modify_trackers(
    df,
    rows_to_change,
    fields_to_remove,
    swap_map,
    fields_to_add,
    output_dir,
    timestamp,
)
# Files are written as outputs/modified_<timestamp>.csv and outputs/backup_<timestamp>.csv
```

### Restore a tracker from history data
```python
from pathlib import Path
import pandas as pd
from tracker_hacker.history_restore import restore_tracker_state, write_restore_report

current_df = pd.read_csv(Path("./exports/tracker_export.csv"), dtype={"Tracker Name Id": str})
history_df = pd.read_csv(Path("./exports/tracker_history.csv"))

tracker_id = "a1Bxx0000001234"
restore_to = "2024-05-01T12:00:00Z"
result = restore_tracker_state(current_df, history_df, tracker_id, restore_to)

output_dir = Path("./outputs")
output_dir.mkdir(exist_ok=True)
write_restore_report(result, output_dir, filename_prefix="restored_tracker")
```

## Output artifacts
- **Modified trackers CSV**: updated rows after removals/swaps/additions.
- **Backup CSV**: original versions of modified rows for rollback.
- **Audit reports**: detailed per-column CSVs listing canonical field occurrences.
- **Restore reports**: human-readable text plus a CSV snapshot of the restored tracker row.

All artifacts are timestamped and placed under `outputs/` to avoid overwriting prior runs.

## Tips and caveats
- Run audits before modifications to ensure you remove or swap the correct fields.
- If JSON in `Filters` is malformed, the CLI writes a diagnostic report to `outputs/` and continues using empty filters for that row.
- When providing manual field paths, use fully qualified API names (for example, `Project__c.Status__c`) to avoid unintended matches.
- Keep helper CSVs small and utf-8 encoded; stray BOM markers or mismatched delimiters can prevent columns from being detected.
